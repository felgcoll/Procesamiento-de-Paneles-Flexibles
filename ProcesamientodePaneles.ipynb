{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de Imágenes\n",
    "\n",
    "El siguiente notebook tiene como objetivo realizar el procesamiento de imágenes correspondiente a paneles flexibles (banderas invertidas), las cuales han sido capturadas en vídeos bajo condiciones de luminosidad deficiente.\n",
    "\n",
    "El dataset consta de varios frames correspondiente al vídeo anteriormente mencionado, los cuales son facilitados para su uso.\n",
    "\n",
    "Para realizar el procesamiento de este tipo de imágenes, se realizaron 2 diferentes conjuntos de operaciones para llegar a un solo objetivo final, recolectar la mayor información posible de la silueta del filamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiente de Trabajo\n",
    "Se importan las librerías a utilizar a lo largo del procesamiento de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from math import sqrt,exp\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.util import img_as_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer conjunto\n",
    "Antes de empezar con el procesamiento se generó una función para recorrer ficheros, la cual recibe como parámetro el directorio al que se va a iterar para guardar la información necesaria y retorna como valor una lista de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a recorrer\n",
    "path_filamentos = '.\\Dataset 1 - Filamentos\\\\'\n",
    "\n",
    "def Ficheros(path):\n",
    "    contenido = os.listdir(path)\n",
    "\n",
    "    #Acumulador del nombre de las imagenes a utilizar\n",
    "    imagenes = []\n",
    "\n",
    "    #Se recorre el path para obtener los nombre y se los aggrega al acumulador, en este caso la lista\n",
    "    for fichero in contenido:\n",
    "        if os.path.isfile(os.path.join(path, fichero)) and fichero.endswith('.jpg'):\n",
    "            imagenes.append(fichero)\n",
    "            \n",
    "    return imagenes        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de la base fija\n",
    "Antes de este paso, se recomienda utilizar la GUI que se encuentra en el archivo 'TrackerPuntos.py' para delimitar la zona a eliminar. Una vez deilimitado los puntos se procedió a genera la función que eliminará la base fija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La variable fuera de la función es el directorio donde se guardaran las imagenes procesadas\n",
    "path_sin_base = '.\\Dataset 2 - Sin Base\\\\' \n",
    "\n",
    "#Se crea una función que nos permita eliminar el soporte del filamento\n",
    "def eliminar_soporte(file_name):\n",
    "    #Se abre la imagen\n",
    "    new_img = cv2.imread(path_filamentos + file_name)\n",
    "\n",
    "    #Se crean 2 cuadrados de diferente dimensión para poder eliminar la parte deseada\n",
    "    new_img = cv2.rectangle(new_img, (750, 1327), (1745, 1725), (20, 25, 30), -1)\n",
    "    new_img = cv2.rectangle(new_img, (500, 1590), (2000, 1725), (20, 25, 30), -1)\n",
    "\n",
    "    #Se guardan los resultados\n",
    "    pathw = path_sin_base + file_name\n",
    "    cv2.imwrite(pathw, new_img)\n",
    "\n",
    "#Se utiliza la función para obtener los fichero que se van a procesar\n",
    "filamentos = Ficheros(path_filamentos)\n",
    "\n",
    "#Se aplica la función a los ficheros\n",
    "for im in filamentos:\n",
    "    eliminar_soporte(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación del ruido en el background de la imagen - Sharpening\n",
    "Con la base fija retirada, se procedió a realizar la eliminación del ruido que se encuentra en el background de cada imagen, además de realizar la operación de 'Sharpening' y guardar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar el resultado\n",
    "path_sin_ruido = '.\\Dataset 3 - Sin Ruido\\\\' \n",
    "\n",
    "#Función para realizar el denoising\n",
    "def denoising(file_name):\n",
    "    \n",
    "    #Se abre el archivo\n",
    "    img = cv2.imread(path_sin_base + file_name)\n",
    "\n",
    "    \"\"\"Se utiliza la función fastNlMeansDenoisingColored, para poder eliminar en cierta\n",
    "    cantidad el ruido que está dentro de la imagen que está pasando por la función\"\"\"\n",
    "    dst = cv2.fastNlMeansDenoisingColored(img, 25, 21, 21, 21, 23)\n",
    "\n",
    "    \"\"\"Se crea un kernel el cual será utilizado para realizar un sharpening de la\n",
    "    imagen luego de realizar el denoising\"\"\"\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    im = cv2.filter2D(dst, -1, kernel)\n",
    "\n",
    "    #Se guardan los resultados\n",
    "    pathw = path_sin_ruido + file_name\n",
    "    cv2.imwrite(pathw, im)\n",
    "    \n",
    "#Se aplica la función a los ficheros\n",
    "for im in filamentos:\n",
    "    denoising(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de la mediana - Ecualización Adaptativa\n",
    "Antes de realizar esta operación se filtró la imagen por medio del uso de un filtro de la media, para continuar con la operación de ecualización adaptativa a escalas grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar el resultado\n",
    "path_ecual = '.\\Dataset 4 - Ecualizacion\\\\' \n",
    "\n",
    "#Se genera la función que va a realizar la ecualización\n",
    "def ecualizer(file_name):\n",
    "    \n",
    "    #Se abre el archivo\n",
    "    img = cv2.imread(path_sin_ruido + file_name, 0)\n",
    "\n",
    "    #Se filtra la imagen con un filtro de la mediana con un kernel 11x11\n",
    "    img = cv2.medianBlur(img, 11, 0)\n",
    "\n",
    "    #Se realiza una ecualización de la imagen para poder captar mejor los constrastes\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl1 = clahe.apply(img)\n",
    "\n",
    "    #Se guardan los resultados\n",
    "    pathw = path_ecual + file_name\n",
    "    cv2.imwrite(pathw, cl1)\n",
    "\n",
    "#Se aplica la función a los ficheros\n",
    "for img in filamentos:\n",
    "    ecualizer(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbralización en el espacio HSV\n",
    "\n",
    "Nuevamente se requirió realizar un ‘trackbar’ para poder identificar los valores del umbral alto y bajo requeridos, ya sea para los valores de HSV (Hue, Saturation y Value), así poder identificar simplemente la parte correspondiente al filamento. (Vease la implementación del ‘trackbar’ en el archivo 'TrackerUmbral.py')\n",
    "\n",
    "Con los valores de los umbrales ya definidos, se procedió a la implementación de la función de la umbralización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar los resultados\n",
    "path_hsv1 = '.\\Dataset 5 - HSV 1\\\\' \n",
    "\n",
    "#Se genera la función que va a realizar la umbralización\n",
    "def hsv1(file_name):\n",
    "   \n",
    "    #Se abre el archivo\n",
    "    img = cv2.imread(path_ecual + file_name)\n",
    "\n",
    "    #Se convierte la imagen de BGR a RGB pues, openCV maneja BGR\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Se realiza un filtro de la mediana con un kernel de 11x11\n",
    "    img = cv2.medianBlur(img, 11, 0)\n",
    "\n",
    "    #Se convierte la imagen de BGR a HSV para realizar la umbralización\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    #Se definen los umbrales altos y bajos para realizar la umbralización\n",
    "    umbral_bajo = (0, 0, 47)\n",
    "    umbral_alto = (179, 255, 255)\n",
    "    \n",
    "    #Se realiza la umbralización\n",
    "    mask = cv2.inRange(img_hsv, umbral_bajo, umbral_alto)\n",
    "    \n",
    "    #Se guardan los resultados\n",
    "    pathw = path_hsv1 + file_name\n",
    "    cv2.imwrite(pathw, mask)\n",
    "\n",
    "    \n",
    "#Se aplica la función a los ficheros\n",
    "for img in filamentos:\n",
    "    hsv1(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Conjunto\n",
    "\n",
    "En el segundo paso se retomó el dataset en el paso 4, además que este segundo conjunto consta con el uso de otro lenguaje de programación (MATLab) para ciertas operaciones particulares.\n",
    "\n",
    "### Low Pass Filter\n",
    "Se utilizó la transformada de Fourier, para pasar al dominio de la frecuencia. En este caso al tratarse de pixeles, se utilizó una transformada discreta al no tratarse de valores continuos. El algoritmo a implementar fue el ‘Fast Fourier Transform’ el cual se encuentra disponible en la librería ‘scipy’ de Python. Esta operación permitió que se realizara un ‘low pass filter’ el cual permite que los bordes tengan una mejor definición y así poder segmentarlos de mejor manera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar los resultados\n",
    "path_LPF = '.\\Dataset 6 - FFT\\\\' \n",
    "\n",
    "#Se crea la función que para realizar el filtro\n",
    "def lpf(file_name):\n",
    "    \n",
    "    #Distancia\n",
    "    def distance(point1,point2):\n",
    "        return sqrt((point1[0]-point2[0])**2 + (point1[1]-point2[1])**2)\n",
    "    \n",
    "    #Filtro ideal\n",
    "    def idealFilterLP(D0,imgShape):\n",
    "        base = np.zeros(imgShape[:2])\n",
    "        rows, cols = imgShape[:2]\n",
    "        center = (rows/2,cols/2)\n",
    "        for x in range(cols):\n",
    "            for y in range(rows):\n",
    "                if distance((y,x),center) < D0:\n",
    "                    base[y,x] = 1\n",
    "        return base\n",
    "    \n",
    "    #Se abre el fichero\n",
    "    img = cv2.imread(path_ecual + file_name, 0)\n",
    "    \n",
    "    #Fast Fourier Transform\n",
    "    original = np.fft.fft2(img)\n",
    "    center = np.fft.fftshift(original)\n",
    "    \n",
    "    #Low pass filter\n",
    "    LowPass = idealFilterLP(50,img.shape)\n",
    "    LowPassCenter = center * idealFilterLP(50,img.shape)\n",
    "    LowPass = np.fft.ifftshift(LowPassCenter)\n",
    "    \n",
    "    #Operación inversa\n",
    "    inverse_LowPass = np.fft.ifft2(LowPass)\n",
    "    \n",
    "    #Se pasa del dominio de la frecuencia al discreto\n",
    "    filtered_img = np.abs(inverse_LowPass)\n",
    "    filtered_img -= filtered_img.min()\n",
    "    filtered_img = filtered_img*255 / filtered_img.max()\n",
    "    filtered_img = filtered_img.astype(np.uint8)\n",
    "    \n",
    "    #Se guardan los resultados\n",
    "    pathw = path_LPF  + file_name\n",
    "    cv2.imwrite(pathw, filtered_img)\n",
    "\n",
    "#Se aplica la función a los ficheros\n",
    "for img in filamentos:\n",
    "    lpf(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbralización en el espacio HSV\n",
    "Se realizó lo mismo que en la primera umbralización del Conjunto 1 de operaciones, con la variación en los umbrales, pues el análisis ahora es a los frames que pasaron por un 'Low pass Filter'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar los resultados\n",
    "path_hsv2 = '.\\Dataset 7 - HSV 2\\\\' \n",
    "\n",
    "#Se define la función que va a realizar la umbralización\n",
    "def hsv2(file_name):\n",
    "    \n",
    "    #Se abre el fichero\n",
    "    img = cv2.imread(path_LPF + file_name)\n",
    "\n",
    "    #Se convierte la imagen de BGR a RGB pues, openCV maneja BGR\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Se realiza un filtro de la mediana con un kernel de 11x11\n",
    "    img = cv2.medianBlur(img, 11, 0)\n",
    "\n",
    "    #Se convierte la imagen de BGR a HSV para realizar la umbralización\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    umbral_bajo = (0, 0, 150)\n",
    "    umbral_alto = (179, 255, 255)\n",
    "    \n",
    "    #Se realiza la umbralización\n",
    "    mask = cv2.inRange(img_hsv, umbral_bajo, umbral_alto)\n",
    "\n",
    "    pathw = path_hsv2 + file_name\n",
    "    cv2.imwrite(pathw, mask)\n",
    "\n",
    "#Se aplica la función a los ficheros\n",
    "for img in filamentos:\n",
    "    hsv2(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superposición de resultados\n",
    "Una vez obtenido el resultado del paso anterior, los dataset correspondientes a la umbralización de la operación 1 y operación 2 son superpuestos, pues información que no pudo ser segmentada dentro de la operación 1 lo fue posible en la operación 2 y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar los resultados\n",
    "path_merge = '.\\Dataset 8 - Merge\\\\' \n",
    "\n",
    "#Directorios a abrir los archivos a combinar\n",
    "path_hsv1 = '.\\Dataset 5 - HSV 1\\\\'\n",
    "path_hsv2 = '.\\Dataset 7 - HSV 2\\\\'\n",
    "\n",
    "#Se define la función que va a superponer los resultados\n",
    "def merge(file_name):\n",
    "\n",
    "    #Se abren instancias de las imagenes a combinar\n",
    "    img = Image.open(path_hsv1 + file_name)\n",
    "    background = Image.open(path_hsv2 + file_name)\n",
    "    \n",
    "    #Se realiza la superposición\n",
    "    background.paste(img, (0, 0), img)\n",
    "    \n",
    "    #Se guardan resultados\n",
    "    pathw = path_merge + file_name\n",
    "    background.save(pathw)\n",
    "    \n",
    "#Se aplica la función a los ficheros\n",
    "for img in filamentos:\n",
    "    merge(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilation\n",
    "Se realizó la operación de dilatación, lo cual permitió unir ciertas partes de los filamentos segmentados que se encontraban dispersas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar los resultados\n",
    "path_dil = '.\\Dataset 9 - Dilatacion\\\\' \n",
    "\n",
    "#Se define la función que va a realizar la operación de dilatación\n",
    "def dilation(file_name):\n",
    "    \n",
    "    #Se abre la imagen\n",
    "    img = cv2.imread(path_merge + file_name)\n",
    "    \n",
    "    #Se define el kernel con el que se va a trabajar\n",
    "    kernal = np.ones((13, 13), np.uint8)\n",
    "    \n",
    "    #Se aplica la operación morfológica y sus respectivas iteraciones\n",
    "    dilation = cv2.dilate(img, kernal, iterations=7)\n",
    "    \n",
    "    #Se guardan resultados\n",
    "    pathw = path_dil + file_name\n",
    "    cv2.imwrite(pathw, dilation)\n",
    "\n",
    "#Se aplica la función a los ficheros\n",
    "for img in filamentos:\n",
    "    dilation(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erosion - Blob Analysis\n",
    "El pre-procesamiento de la erosión se lo realizó para evitar que ciertos ‘blobs’, sigan en contacto con la figura del filamento y evitar que esto no permita segmentar de correcta la figura de las banderas.\n",
    "\n",
    "Una vez finalizado el pre-procesamiento, se procedió a eliminar los ‘blobs’ que se encontraban alrededor de los frames analizados, pues este ruido evitaría que la operación posterior se lleve a cabo de una manera eficiente, pues es requerida simplemente la forma del filamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio a guardar los resultados\n",
    "path_blob= '.\\Dataset 10 - Blob Analysis\\\\' \n",
    "\n",
    "#Se define la función que va a realizar la operación mencionada\n",
    "def blob(file_name):\n",
    "    \n",
    "    #Se abre el fichero\n",
    "    img = cv2.imread(path_dil + file_name)\n",
    "    \n",
    "    #Se define el kernel con el que se va a realizar la erosion\n",
    "    kernal = np.ones((3, 3), np.uint8)\n",
    "    \n",
    "    #Se aplica la operacion morfológica y sus respectivas iteraciones\n",
    "    erosion = cv2.erode(img, kernal, iterations=3)\n",
    "    \n",
    "    \"\"\"\n",
    "    Se convierte la variable debido a que la librería 'scipy' no trabaja con variables tipo 'uint8' como \n",
    "    lo hace la libería 'OpenCV'\n",
    "    \"\"\"\n",
    "    image = img_as_float(erosion)\n",
    "    \n",
    "    #Se definen los parámetros para realizar la segmentación de areas\n",
    "    label_objects, nb_labels = ndi.label(image)\n",
    "    sizes = np.bincount(label_objects.ravel())\n",
    "    \n",
    "    #Se define las áreas a eliminar\n",
    "    mask_sizes = sizes > 350000\n",
    "    mask_sizes[0] = 0\n",
    "    clean = mask_sizes[label_objects]\n",
    "    \n",
    "    #El resultado se vuelve a transformar a valor tipo 'uint8'\n",
    "    clean_2 = img_as_ubyte(clean)\n",
    "    \n",
    "    #Se guardan resultados\n",
    "    pathw = path_blob + file_name\n",
    "    cv2.imwrite(pathw, clean_2)\n",
    "\n",
    "#Se aplica la función a los ficheros  \n",
    "for img in filamentos:\n",
    "    blob(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuacion\n",
    "A partir de este paso fue requerida la implementación del lenguaje de programación de MATLab, pues para las operaciones de esqueletonización y eliminación de 'spurs' se requirió el uso de la 'Image Processing Toolbox' de MATLab debido a las funciones que permitían un mejor desempeño para realizar las operaciones anteriormente mencionadas. Para ver su implementación revisar el archivo 'Esqueletonizacion.m' en el repositorio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
